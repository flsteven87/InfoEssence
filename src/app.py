import streamlit as st
import psycopg2
from psycopg2.extras import RealDictCursor
from config.settings import DATABASE_URL
import logging
from datetime import timedelta
import os
import pandas as pd
from utils.file_utils import sanitize_filename
import html

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é€£æ¥åˆ°æ•¸æ“šåº«
@st.cache_resource
def init_connection():
    return psycopg2.connect(DATABASE_URL)

conn = init_connection()

# æŸ¥è©¢æ•¸æ“š
@st.cache_data(ttl=600)
def run_query(query, params=None):
    global conn
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(query, params)
            return cur.fetchall()
    except psycopg2.Error as e:
        logger.error(f"è³‡æ–™åº«éŒ¯èª¤: {e}")
        st.error("ç™¼ç”Ÿè³‡æ–™åº«éŒ¯èª¤ï¼Œæ­£åœ¨å˜—è©¦é‡æ–°é€£æ¥...")
        conn.rollback()  # å›æ»¾äº¤æ˜“
        conn = init_connection()  # é‡æ–°å»ºç«‹é€£æ¥
        try:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute(query, params)
                return cur.fetchall()
        except psycopg2.Error as e:
            logger.error(f"è©¦å¾Œä»ç„¶ç™¼ç”ŸéŒ¯èª¤: {e}")
            st.error("ç„¡æ³•é€£æ¥åˆ°è³‡æ–™åº«ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
            return []

# æ–°å¢å‡½æ•¸ï¼šç²å–æœ€æ–°çš„ CSV æª”æ¡ˆ
def get_latest_csv():
    csv_dir = "chosen_news/"
    csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]
    if not csv_files:
        return None
    latest_csv = max(csv_files, key=lambda x: os.path.getctime(os.path.join(csv_dir, x)))
    return os.path.join(csv_dir, latest_csv)

# ä¿®æ”¹å‡½æ•¸ï¼šè®€å– CSV æª”æ¡ˆä¸¦è¿”å›é‡è¦æ–°èçš„å­—å…¸
@st.cache_data(ttl=600)
def get_important_news():
    csv_path = get_latest_csv()
    if not csv_path:
        logger.warning("æœªæ‰¾åˆ° CSV æª”æ¡ˆ")
        return {}, None
    try:
        df = pd.read_csv(csv_path)
        if 'id' not in df.columns:
            logger.error(f"CSV æª”æ¡ˆ {csv_path} ä¸­ç¼ºå°‘å¿…è¦æ¬„ä½")
            st.warning("ç„¡æ³•è¼‰å…¥é‡è¦æ–°èåˆ—è¡¨ï¼Œè«‹æª¢æŸ¥ CSV æª”æ¡ˆæ ¼å¼")
            return {}, os.path.basename(csv_path)
        # å°‡ id è½‰æ›ç‚ºå­—ç¬¦ä¸²
        df['id'] = df['id'].astype(str)
        important_news = df.set_index('id').to_dict(orient='index')
        logger.info(f"å·²è¼‰å…¥ {len(important_news)} æ¢é‡è¦æ–°è")
        return important_news, os.path.basename(csv_path)
    except Exception as e:
        logger.error(f"è®€å– CSV æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        st.error("è®€å–é‡è¦æ–°èåˆ—è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤")
        return {}, os.path.basename(csv_path)

# æ–°å¢å‡½æ•¸ï¼šç²å–æœ€æ–°çš„ Instagram CSV æª”æ¡ˆ
def get_latest_instagram_csv():
    csv_dir = "./instagram_posts/"
    csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]
    if not csv_files:
        return None
    latest_csv = max(csv_files, key=lambda x: os.path.getctime(os.path.join(csv_dir, x)))
    return os.path.join(csv_dir, latest_csv)

# æ–°å¢å‡½æ•¸ï¼šè®€å– Instagram CSV æª”æ¡ˆä¸¦è¿”å›æ˜ å°„
@st.cache_data(ttl=600)
def get_instagram_posts():
    csv_path = get_latest_instagram_csv()
    if not csv_path:
        logger.warning("æœªæ‰¾åˆ° Instagram CSV æª”æ¡ˆ")
        return {}, None
    try:
        df = pd.read_csv(csv_path)
        if 'id' not in df.columns or 'ig_title' not in df.columns or 'ig_caption' not in df.columns:
            logger.error(f"Instagram CSV æª”æ¡ˆ {csv_path} ä¸­ç¼ºå°‘å¿…è¦æ¬„ä½")
            st.warning("ç„¡æ³•è¼‰å…¥ Instagram è²¼æ–‡åˆ—è¡¨ï¼Œè«‹æª¢æŸ¥ CSV æª”æ¡ˆæ ¼å¼")
            return {}, os.path.basename(csv_path)
        df['id'] = df['id'].astype(str)
        instagram_posts = df.set_index('id').to_dict(orient='index')
        logger.info(f"å·²è¼‰å…¥ {len(instagram_posts)} æ¢ Instagram è²¼æ–‡")
        return instagram_posts, os.path.basename(csv_path)
    except Exception as e:
        logger.error(f"è®€å– Instagram CSV æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        st.error("è®€å– Instagram è²¼æ–‡åˆ—è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤")
        return {}, os.path.basename(csv_path)

# ä¸»æ‡‰ç”¨
def main():
    st.title("GlobalNews for Taiwan")

    # å´é‚Šæ¬„
    st.sidebar.title("ç¯©é¸é¸é …")
    
    media_query = "SELECT DISTINCT media.name FROM news JOIN media ON news.media_id = media.id"
    media_list = [row['name'] for row in run_query(media_query) if row]
    
    if not media_list:
        st.sidebar.error("ç„¡æ³•è¼‰å…¥åª’é«”åˆ—è¡¨")
        return

    selected_media = st.sidebar.multiselect("é¸æ“‡åª’é«”", media_list)

    # æ—¥æœŸç¯„åœé¸æ“‡
    start_date = st.sidebar.date_input("é–‹å§‹æ—¥æœŸ")
    end_date = st.sidebar.date_input("çµæŸæ—¥æœŸ")

    # æ§‹å»ºæŸ¥è©¢
    query = """
    SELECT news.id, news.title, news.ai_title, news.ai_summary, news.link, 
           media.name as media_name, feeds.name as feed_name, news.published_at
    FROM news
    JOIN media ON news.media_id = media.id
    JOIN feeds ON news.feed_id = feeds.id
    WHERE news.published_at >= %s AND news.published_at < %s
    """
    # å°‡çµæŸæ—¥æœŸåŠ ï¿½ï¿½å¤©ï¼Œä»¥åŒ…å«æ•´å€‹çµæŸæ—¥æœŸ
    params = [start_date, end_date + timedelta(days=1)]

    if selected_media:
        query += " AND media.name IN %s"
        params.append(tuple(selected_media))

    query += " ORDER BY news.published_at DESC"

    # åŸ·è¡ŒæŸ¥è©¢
    news_items = run_query(query, params)

    # ç²å–é‡è¦æ–°èçš„å­—å…¸å’Œ CSV æª”æ¡ˆåç¨±
    important_news, csv_filename = get_important_news()
    
    # ç²å– Instagram è²¼æ–‡çš„å­—å…¸å’Œ CSV æª”æ¡ˆåç¨±
    instagram_posts, instagram_csv_filename = get_instagram_posts()

    # é¡¯ç¤ºæ­£åœ¨ä½¿ç”¨çš„ CSV æª”æ¡ˆåç¨±
    if csv_filename:
        st.sidebar.info(f"æ­£åœ¨ä½¿ç”¨çš„é‡è¦æ–°è CSV æª”æ¡ˆ: {csv_filename}")
    else:
        st.sidebar.warning("æœªæ‰¾åˆ°é‡è¦æ–°è CSV æª”æ¡ˆ")

    if instagram_csv_filename:
        st.sidebar.info(f"æ­£åœ¨ä½¿ç”¨çš„ Instagram CSV æª”æ¡ˆ: {instagram_csv_filename}")
    else:
        st.sidebar.warning("æœªæ‰¾åˆ° Instagram CSV æª”æ¡ˆ")

    if not important_news:
        st.warning("æœªæ‰¾åˆ°é‡è¦æ–°èï¼Œè«‹ç¢ºä¿ CSV æª”æ¡ˆå­˜åœ¨ä¸”æ ¼å¼æ­£ç¢º")

    # é¡¯ç¤ºæ–°è
    for item in news_items:
        item_id = str(item['id'])
        is_important = item_id in important_news
        has_instagram_post = item_id in instagram_posts
        
        # æ ¼å¼åŒ–ç™¼å¸ƒæ™‚é–“
        published_time = item['published_at'].strftime('%Y-%m-%d %H:%M')
        
        title_display = f"{item['id']} - {item['ai_title']} - {published_time}"
        if is_important:
            title_display += " ğŸ”¥"
        if has_instagram_post:
            title_display += " ğŸ“¸"

        with st.expander(title_display):
            # å¦‚æœæ˜¯é‡è¦æ–°èï¼Œé¡¯ç¤ºåœ–ç‰‡
            if is_important:
                image_dir = "./image/"
                media_dir = sanitize_filename(item['media_name'])
                feed_dir = sanitize_filename(item.get('feed_name', ''))
                image_path = os.path.join(image_dir, media_dir, feed_dir)
                image_files = [f for f in os.listdir(image_path) if f.startswith(f"{item['id']}_") and f.endswith("_integrated.png")]
                if image_files:
                    image_file = image_files[0]
                    full_image_path = os.path.join(image_path, image_file)
                    st.image(full_image_path, caption="æ–°èç›¸é—œåœ–ç‰‡")

            # é¡¯ç¤ºæ¨™é¡Œå’Œæ‘˜è¦
            if has_instagram_post:
                display_title = instagram_posts[item_id]['ig_title']
                display_summary = instagram_posts[item_id]['ig_caption']
            else:
                display_title = item['ai_title']
                display_summary = item['ai_summary']

            # ç¢ºä¿ display_title å’Œ display_summary ä¸æ˜¯ None
            display_title = str(display_title) if display_title is not None else ""
            display_summary = str(display_summary) if display_summary is not None else ""

            # è™•ç†æ‘˜è¦ä¸­çš„ hashtag
            hashtag_index = display_summary.find('#')
            if hashtag_index != -1:
                display_summary = display_summary[:hashtag_index] + '<br><br>' + display_summary[hashtag_index:]
            else:
                display_summary += '<br><br>'
            display_summary += '#GlobalNewsTaiwan'

            # åœ¨é¡¯ç¤ºä¹‹å‰é€²è¡Œ HTML è½‰ç¾©
            display_title = html.escape(display_title)
            display_summary = html.escape(display_summary).replace('&lt;br&gt;', '<br>')
            media_name = html.escape(item['media_name'])
            link = html.escape(item['link'])

            st.write(f"""
            <div style="border: 1px solid #ddd; padding: 10px; margin-bottom: 10px;">
                <h3>{display_title}</h3>
                <p>{display_summary}</p>
                <p><strong>ä¾†æº:</strong> {media_name}</p>
                <p><strong>ç™¼å¸ƒæ™‚é–“:</strong> {published_time}</p>
                <p><a href="{link}" target="_blank">é–±è®€åŸæ–‡</a></p>
            </div>
            """, unsafe_allow_html=True)

    # åœ¨é é¢åº•éƒ¨é¡¯ç¤ºè¼‰å…¥çš„é‡è¦æ–°èå’Œ Instagram è²¼æ–‡æ•¸é‡
    st.info(f"å·²è¼‰å…¥ {len(important_news)} æ¢é‡è¦æ–°èå’Œ {len(instagram_posts)} æ¢ Instagram è²¼æ–‡")

if __name__ == "__main__":
    main()
